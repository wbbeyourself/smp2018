{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "BASE = '/home/wb/smp2018'\n",
    "sys.path.append(BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import word2vec\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from init.config import Config\n",
    "from tools import time_cost\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "from pyltp import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base = '/home/wb/text-classification/data'\n",
    "\n",
    "src = data_base + '/News_label.txt'\n",
    "\n",
    "all_path = data_base + '/all.csv'\n",
    "\n",
    "train_path = data_base + '/train.csv'\n",
    "\n",
    "test_path = data_base + '/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.cache_dir = data_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.word_vocab_path = data_base + '/word_vocab.pk'\n",
    "cfg.char_vocab_path = data_base + '/char_vocab.pk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.word_embed_path = data_base + '/word_embed.pk'\n",
    "cfg.char_embed_path = data_base + '/char_embed.pk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_all_data():\n",
    "    train_all_data = pd.read_csv(all_path, sep='\\t')\n",
    "    return train_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_w2vc(overwrite=True):\n",
    "    if overwrite:\n",
    "        if os.path.exists(cfg.cache_dir + '/w2v_content_word.txt'):\n",
    "            os.remove(cfg.cache_dir + '/w2v_content_word.txt')\n",
    "        if os.path.exists(cfg.cache_dir + '/w2v_content_char.txt'):\n",
    "            os.remove(cfg.cache_dir + '/w2v_content_char.txt')\n",
    "\n",
    "        train_data = get_train_all_data()\n",
    "\n",
    "        train_content = train_data[\"content\"]\n",
    "\n",
    "        print(\"len of all contents\", len(train_content))\n",
    "\n",
    "        def applyParallel(contents, func, n_thread):\n",
    "            with Parallel(n_jobs=n_thread) as parallel:\n",
    "                parallel(delayed(func)(c) for c in contents)\n",
    "\n",
    "        def word_content(content):\n",
    "            with open(cfg.cache_dir + \"/w2v_content_word.txt\", \"a+\") as f:\n",
    "                f.writelines(content.lower())\n",
    "                f.writelines('\\n')\n",
    "\n",
    "        def char_content(content):\n",
    "            with open(cfg.cache_dir + \"/w2v_content_char.txt\", \"a+\") as f:\n",
    "                content = content.lower().replace(\" \", \"\")\n",
    "                f.writelines(\" \".join(content))\n",
    "                f.writelines(\"\\n\")\n",
    "\n",
    "        applyParallel(train_content, word_content, 25)\n",
    "        applyParallel(train_content, char_content, 25)\n",
    "\n",
    "\n",
    "    # word vector train\n",
    "    model = gensim.models.Word2Vec(\n",
    "        LineSentence(cfg.cache_dir + \"/w2v_content_word.txt\"),\n",
    "        size=vec_dim,\n",
    "        window=5,\n",
    "        min_count=1,\n",
    "        workers=multiprocessing.cpu_count()\n",
    "    )\n",
    "    model.save(cfg.cache_dir + \"/content_w2v_word.model\")\n",
    "\n",
    "    # char vector train\n",
    "    model = gensim.models.Word2Vec(\n",
    "        LineSentence(cfg.cache_dir + '/w2v_content_char.txt'),\n",
    "        size=vec_dim,\n",
    "        window=5,\n",
    "        min_count=1,\n",
    "        workers=multiprocessing.cpu_count()\n",
    "    )\n",
    "    model.save(cfg.cache_dir + \"/content_w2v_char.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- len of all contents 48,480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_w2vc(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "time cost 0hour 0minute\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "time_cost(t0, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_emb(use_opened=False, overwriter=False):\n",
    "\n",
    "    vocab = pickle.load(open(cfg.word_vocab_path, 'rb'))\n",
    "    print(len(vocab))\n",
    "\n",
    "    if use_opened:\n",
    "        word_emb = [np.random.uniform(0, 0, 200) for j in range(len(vocab)+1)]\n",
    "        model = word2vec.load(cfg.open_w2v_path)\n",
    "    else:\n",
    "        word_emb = [np.random.uniform(0, 0, 256) for j in range(len(vocab)+1)]\n",
    "        model = gensim.models.Word2Vec.load(cfg.cache_dir + \"/content_w2v_word.model\")\n",
    "    num = 0\n",
    "    \n",
    "    word_emb = np.array(word_emb)\n",
    "    \n",
    "    for word in vocab:\n",
    "        index = vocab[word]\n",
    "        if word in model:\n",
    "            word_emb[index] = np.array(model[word])\n",
    "            num += 1\n",
    "        else:\n",
    "            word_emb[index] = np.random.uniform(-0.5, 0.5, 256)\n",
    "    print(\"word number: \", num)\n",
    "    print(\"vocab size:\", len(vocab))\n",
    "    print(\"shape of word_emb\", np.shape(word_emb))\n",
    "    if overwriter:\n",
    "        with open(cfg.word_embed_path, 'wb') as f:\n",
    "            pickle.dump(word_emb, f)\n",
    "            print(\"size of embedding_matrix: \", len(word_emb))\n",
    "            print(\"word_embedding finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- size of word embedding_matrix:  655,382\n",
    "- shape of word_emb (655,382, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_word_emb(False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "time cost 0hour 0minute\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_cost(t0, time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_char_emb(overwriter=False):\n",
    "\n",
    "    vocab = pickle.load(open(cfg.char_vocab_path, 'rb'))\n",
    "    char_emb = [np.random.uniform(0, 0, 256) for j in range(len(vocab)+1)]\n",
    "    char_emb = np.array(char_emb)\n",
    "    model = gensim.models.Word2Vec.load(cfg.cache_dir + \"/content_w2v_char.model\")\n",
    "    num = 0\n",
    "    for char in vocab:\n",
    "        index = vocab[char]\n",
    "        if char in model:\n",
    "            char_emb[index] = np.array(model[char])\n",
    "            num += 1\n",
    "        else:\n",
    "            char_emb[index] = np.random.uniform(-0.5, 0.5, 256)\n",
    "    print(\"char number: \", num)\n",
    "    print(\"vocab size:\", len(vocab))\n",
    "    print(\"shape of char_emb\", np.shape(char_emb))\n",
    "    if overwriter:\n",
    "        with open(cfg.char_embed_path, 'wb') as f:\n",
    "            pickle.dump(char_emb, f)\n",
    "            print(\"size of embedding_matrix: \", len(char_emb))\n",
    "            print(\"char_embedding finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- size of char embedding_matrix:  9,888\n",
    "- shape of char_emb (9,888, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_char_emb(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "time cost 0hour 0minute\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_cost(t0, time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_vocab(overwriter=False):\n",
    "    word_freq = defaultdict(int)\n",
    "\n",
    "    train_data = get_train_all_data()\n",
    "    train_content = train_data[\"content\"]\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    for line in train_content:\n",
    "        line = line.lower().strip()\n",
    "        words = line.split(\" \")\n",
    "        for word in words:\n",
    "            if \" \" == word or \"\" == word:\n",
    "                continue\n",
    "            word_freq[word] += 1\n",
    "    \n",
    "    time_cost(start, time.time())\n",
    "\n",
    "    \n",
    "    vocab = {}\n",
    "    i = 1\n",
    "    min_freq = 1\n",
    "    for word, freq in word_freq.items():\n",
    "        if freq >= min_freq:\n",
    "            vocab[word] = i\n",
    "            i += 1\n",
    "    vocab['NUM'] = i\n",
    "    vocab['UNK'] = i+1\n",
    "    print(\"size of vocab:\", len(vocab))\n",
    "\n",
    "    if overwriter:\n",
    "        vocab_file = cfg.cache_dir + '/word_vocab.pk'\n",
    "        with open(vocab_file, 'wb') as f:\n",
    "            pickle.dump(vocab, f)\n",
    "        print(\"finish to create vocab !\")\n",
    "        time_cost(start, time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- size of word vocab: 655,381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_word_vocab(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "time cost 0hour 0minute\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "time_cost(t0, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_char_vocab(overwriter=False):\n",
    "    char_freq = defaultdict(int)\n",
    "\n",
    "    train_data = get_train_all_data()\n",
    "    train_content = train_data[\"content\"]\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    for line in train_content:\n",
    "        line = line.lower().strip()\n",
    "        line = line.replace(\" \", \"\")\n",
    "        chars_line = \" \".join(line)\n",
    "        chars = chars_line.split(\" \")\n",
    "        for char in chars:\n",
    "            if \" \" == char or \"\" == char:\n",
    "                continue\n",
    "            char_freq[char] += 1\n",
    "    \n",
    "    time_cost(start, time.time())\n",
    "\n",
    "    \n",
    "    vocab = {}\n",
    "    i = 1\n",
    "    min_freq = 1\n",
    "    for char, freq in char_freq.items():\n",
    "        if freq >= min_freq:\n",
    "            vocab[char] = i\n",
    "            i += 1\n",
    "    vocab['NUM'] = i\n",
    "    vocab['UNK'] = i+1\n",
    "    print(vocab)\n",
    "    print(\"size of vocab:\", len(vocab))\n",
    "\n",
    "    if overwriter:\n",
    "        vocab_file = cfg.cache_dir + '/char_vocab.pk'\n",
    "        with open(vocab_file, 'wb') as f:\n",
    "            pickle.dump(vocab, f)\n",
    "        time_cost(start, time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- size of char vocab: 9,887"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_vocab = create_char_vocab(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(d, save_path):\n",
    "    f = open(save_path, \"w\")\n",
    "    for key in d:\n",
    "        f.write(str(key)+\",\"+ str(d[key]) +'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sentence_num_length():\n",
    "    train_data = get_train_all_data()\n",
    "    train_content = train_data[\"content\"]\n",
    "    train_labels = train_data[\"label\"]\n",
    "\n",
    "    train_num_dict = defaultdict(int)\n",
    "    good_train_num_dict = defaultdict(int)\n",
    "    poor_train_num_dict = defaultdict(int)\n",
    "    bad_train_num_dict = defaultdict(int)\n",
    "\n",
    "    for i in range(len(train_content)):\n",
    "        content = train_content[i].lower().strip()\n",
    "        sentences = SentenceSplitter.split(content)\n",
    "        sent_num = len(sentences)\n",
    "        train_num_dict[sent_num] += 1\n",
    "        \n",
    "        if train_labels[i] == 0:\n",
    "            good_train_num_dict[sent_num] += 1\n",
    "        elif train_labels[i] == 1:\n",
    "            poor_train_num_dict[sent_num] += 1\n",
    "        elif train_labels[i] == 2:\n",
    "            bad_train_num_dict[sent_num] += 1\n",
    "        else:\n",
    "            print(\"wrong\", train_labels[i])\n",
    "    save_dict(train_num_dict, cfg.cache_dir + \"/train_sen_num.csv\")\n",
    "    save_dict(good_train_num_dict, cfg.cache_dir + \"/good_sen_num.csv\")\n",
    "    save_dict(poor_train_num_dict, cfg.cache_dir + \"/poor_sen_num.csv\")\n",
    "    save_dict(bad_train_num_dict, cfg.cache_dir + \"/bad_sen_num.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_sentence_num_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_sentence_length():\n",
    "    train_data = get_train_all_data()\n",
    "    train_content = train_data[\"content\"]\n",
    "    train_labels = train_data[\"label\"]\n",
    "\n",
    "    train_word_num_dict = defaultdict(int)\n",
    "    good_word_num_dict = defaultdict(int)\n",
    "    poor_word_num_dict = defaultdict(int)\n",
    "    bad_word_num_dict = defaultdict(int)\n",
    "\n",
    "    for i in range(len(train_content)):\n",
    "        content = train_content[i].lower().strip()\n",
    "        sentences = SentenceSplitter.split(content)\n",
    "        word_count = 0\n",
    "        for sent in sentences:\n",
    "            sent = sent.strip()\n",
    "            word_count += len(sent.split(\" \"))\n",
    "        train_word_num_dict[word_count] += 1\n",
    "        if train_labels[i] == 0:\n",
    "            good_word_num_dict[word_count] += 1\n",
    "        elif train_labels[i] == 1:\n",
    "            poor_word_num_dict[word_count] += 1\n",
    "        elif train_labels[i] == 2:\n",
    "            bad_word_num_dict[word_count] += 1\n",
    "        else:\n",
    "            print(\"wrong\", train_labels[i])\n",
    "    save_dict(train_word_num_dict, cfg.cache_dir + \"/train_word_sen_len.csv\")\n",
    "    save_dict(good_word_num_dict, cfg.cache_dir + \"/good_word_sen_len.csv\")\n",
    "    save_dict(poor_word_num_dict, cfg.cache_dir + \"/poor_word_sen_len.csv\")\n",
    "    save_dict(bad_word_num_dict, cfg.cache_dir + \"/bad_word_sen_len.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_word_sentence_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_char_sentence_length():\n",
    "    train_data = get_train_all_data()\n",
    "    train_content = train_data[\"content\"]\n",
    "    train_labels = train_data[\"label\"]\n",
    "\n",
    "    train_char_num_dict = defaultdict(int)\n",
    "    good_char_num_dict = defaultdict(int)\n",
    "    poor_char_num_dict = defaultdict(int)\n",
    "    bad_char_num_dict = defaultdict(int)\n",
    "\n",
    "    for i in range(len(train_content)):\n",
    "        content = train_content[i].lower().strip()\n",
    "        sentences = SentenceSplitter.split(content)\n",
    "        char_count = 0\n",
    "        for sent in sentences:\n",
    "            sent = sent.strip()\n",
    "            line = sent.replace(\" \", \"\")\n",
    "            chars_line = \" \".join(line)\n",
    "            chars = chars_line.split(\" \")\n",
    "            char_count += len(chars)\n",
    "\n",
    "        train_char_num_dict[char_count] += 1\n",
    "        if train_labels[i] == 0:\n",
    "            good_char_num_dict[char_count] += 1\n",
    "        elif train_labels[i] == 1:\n",
    "            poor_char_num_dict[char_count] += 1\n",
    "        elif train_labels[i] == 2:\n",
    "            bad_char_num_dict[char_count] += 1\n",
    "        else:\n",
    "            print(\"wrong\", train_labels[i])\n",
    "    save_dict(train_char_num_dict, cfg.cache_dir + \"/train_char_sen_len.csv\")\n",
    "    save_dict(good_char_num_dict, cfg.cache_dir + \"/good_char_sen_len.csv\")\n",
    "    save_dict(poor_char_num_dict, cfg.cache_dir + \"/poor_char_sen_len.csv\")\n",
    "    save_dict(bad_char_num_dict, cfg.cache_dir + \"/bad_char_sen_len.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_char_sentence_length()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化数据界面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.read_csv(cfg.cache_dir + \"/train_char_sen_len.csv\", header=None)\n",
    "\n",
    "word_df = word_df.sort_values(by=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3699</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>12</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>13</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>14</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>15</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>16</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>17</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>18</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>19</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>23</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>24</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>25</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>27</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>28</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>29</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>30</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>31</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>32</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>14173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>14197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>14433</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>14675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>14804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3866</th>\n",
       "      <td>14809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>15357</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>15650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>15790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>15953</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3927</th>\n",
       "      <td>16349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4035</th>\n",
       "      <td>16447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>16521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>16680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3430</th>\n",
       "      <td>16698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>16856</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3671</th>\n",
       "      <td>16992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>17139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>17261</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3711</th>\n",
       "      <td>17562</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3712</th>\n",
       "      <td>17825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3151</th>\n",
       "      <td>18444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>19123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>19463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>21118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>21862</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>25563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823</th>\n",
       "      <td>36692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>37376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4013</th>\n",
       "      <td>40932</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4046 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1\n",
       "2070      2    3\n",
       "1325      4   13\n",
       "3699      5    1\n",
       "1170      6    8\n",
       "3716      7    1\n",
       "204       8   22\n",
       "855       9   20\n",
       "618      10   50\n",
       "189      11   30\n",
       "451      12   54\n",
       "540      13   58\n",
       "294      14   79\n",
       "351      15   57\n",
       "580      16  135\n",
       "180      17   79\n",
       "594      18  153\n",
       "439      19   96\n",
       "34       20  173\n",
       "8        21   92\n",
       "6        22  223\n",
       "388      23  124\n",
       "212      24  215\n",
       "836      25  103\n",
       "18       26  266\n",
       "357      27  102\n",
       "10       28  247\n",
       "86       29  135\n",
       "108      30  314\n",
       "69       31   93\n",
       "39       32  263\n",
       "...     ...  ...\n",
       "3981  14173    1\n",
       "3327  14197    1\n",
       "3357  14433    1\n",
       "3610  14675    1\n",
       "3530  14804    1\n",
       "3866  14809    1\n",
       "3724  15357    1\n",
       "2746  15650    1\n",
       "1405  15790    1\n",
       "3906  15953    1\n",
       "3927  16349    1\n",
       "4035  16447    1\n",
       "3583  16521    1\n",
       "3619  16680    1\n",
       "3430  16698    1\n",
       "2845  16856    1\n",
       "3671  16992    1\n",
       "3484  17139    1\n",
       "2450  17261    2\n",
       "3711  17562    1\n",
       "3712  17825    1\n",
       "3151  18444    1\n",
       "3568  19123    1\n",
       "2506  19463    1\n",
       "3036  21118    1\n",
       "1681  21862    1\n",
       "2616  25563    1\n",
       "3823  36692    1\n",
       "3728  37376    1\n",
       "4013  40932    1\n",
       "\n",
       "[4046 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = word_df.set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc5e586bb00>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sen = sum(word_df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "head1000_sen = sum(word_df.head(2000)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9165841584158416"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head1000_sen / total_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df[2] = word_df.apply(lambda x: x[0] * x[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = sum(word_df.head(2000)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave = total_words / head1000_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619.2711990278153"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
